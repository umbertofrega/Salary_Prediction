{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b2a4d17",
   "metadata": {},
   "source": [
    "## Salary Prediction Dataset \n",
    "\n",
    "Questo progetto si prepone di risolvere il problema della __Salary Prediction__ in versione *Classification*, quindi di raggruppare i dati in due classi:\n",
    "- _Salary <= 50k_ Per le persone il cui slario è predetto inferiore a 50k\n",
    "- _Salary > 50k_ Per l'inverso;\n",
    "\n",
    "Iniziamo aprendo il dataset dal folder apposito e leggendolo con _pandas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(\"dataset\")\n",
    "df = pd.read_csv(\"salary.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5791ab80",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "Cominciamo vedendo in che stato versa il Dataset cosicchè si possa capire che tipo di operazioni vanno svolte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37071c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda976e",
   "metadata": {},
   "source": [
    "Si può notare che tra i tipi delle colonne ci sono principalmente valori _object_, sicuramente servirà un'operazione di *encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bda506e",
   "metadata": {},
   "source": [
    "Strane queste colonne capital-gain e capital-loss, meglio dare un'occhiata più specifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c43b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital-gain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76de57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital-gain'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dda7bf9",
   "metadata": {},
   "source": [
    "Capital-gain e capital-value essere inutili, precisamente, (facendo i conti una sola volta perché il numero di 0 nelle due colonne è lo stesso) si può dire che su 32561 tuple 29849 sono 0.\n",
    "Infatti impostando la semplice proporzione \n",
    "$$\n",
    "\\frac{29849}{32561} \\cdot 100 \\approx 91.6\\%\n",
    "$$  \n",
    "Capiamo che addirittura il _*91.6%*_ dei valori all'interno di queste due colonne è 0, questo è abbastanza per rimuovere entrambe le colonne per rendere il dataset più semplice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c46ed",
   "metadata": {},
   "source": [
    "Per capire più facilmente quanti siano gli zeri a confronto dei valori accettabili ecco anche una rappresentazione grafica, ma prima un leggero setup di plt per avere dei grafici più carini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b220e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': '#1d2021',\n",
    "    'axes.facecolor': '#201d16',\n",
    "    'axes.edgecolor': '#ebdbb2',\n",
    "    'axes.labelcolor': '#ebdbb2',\n",
    "    'xtick.color': '#ebdbb2',\n",
    "    'ytick.color': '#ebdbb2',\n",
    "    'text.color': '#ebdbb2',\n",
    "    'axes.titlecolor': '#ebdbb2',\n",
    "    'grid.color': '#3c3836',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a1667",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6)) \n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[\"capital-loss\"])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df[\"capital-gain\"], kde=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a6b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a85a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"\\nColonna: {col}\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd83d39e",
   "metadata": {},
   "source": [
    "Tramite l'output di questi ultimi metodi è possibile accorgersi che non sono presenti valori _null_, ma sono presenti molti _missing values_ marchiati con il carattere _?_ nelle colonne:\n",
    "- WorkClass\n",
    "- Occupation\n",
    "- Native Coutry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c563af",
   "metadata": {},
   "source": [
    "Inoltre, si può osservare che la colonna _education_ non si differenzia sostanzialmente da _education-num_, se non per il fatto che quest'ultima contiene valori numerici. Considerando che durante il preprocessing andremo ad applicare tecniche di _encoding_ sulle colonne con valori non numerici, è più conveniente mantenere _education-num_. Quest'ultima, infatti, rappresenta già un'ordinamento naturale dei livelli di istruzione, che andrebbe perso utilizzando algoritmi di encoding come il *One Hot Encoding*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b982088",
   "metadata": {},
   "source": [
    "Infine anche la colonna fnlwgt (Final Weight) è inutile perché rappresenta un peso usato nell'analisi demografica dei sondaggi che, nel contesto della classificazione è completamente inutile. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4edd45",
   "metadata": {},
   "source": [
    "Un grafico utile è il boxplot delle colonne non a classi perché sono gli unici che possono presentare veri outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66fe0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(df[[\"age\",\"hours-per-week\"]])\n",
    "plt.title(\"BoxPlot di Age e Hours Per Week\")\n",
    "plt.ylabel(\"Valore Numerico\")\n",
    "plt.xlabel(\"Attributo\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813463a",
   "metadata": {},
   "source": [
    "Ci sono dei valori lontani, ma non irrelistici quindi _non serve pulire gli outlier_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57737d6b",
   "metadata": {},
   "source": [
    "Infine vediamo qualche grafico per farci un'idea della distribuzione del _dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d9f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x=\"salary\")\n",
    "\n",
    "plt.title(\"Distribuzione dei salari\")\n",
    "plt.xlabel(\"Classe Salariale\")\n",
    "plt.ylabel(\"Numero di osservazioni\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6505b21",
   "metadata": {},
   "source": [
    "Da qui si può notare un grande _class imbalance_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de8cff4",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Cominciamo dalla rimozione delle colonne che erano risultate inutili dalla Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6869e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"capital-gain\", \"capital-loss\",\"education\",\"fnlwgt\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4063ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e4e35c",
   "metadata": {},
   "source": [
    "Continuando procediamo alla rimozione dei duplicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e944a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda36236",
   "metadata": {},
   "source": [
    "Prima di darci all'encoding rendiamo più facile le operazioni trasformando i _missing values ' ?'_  in _np.nan_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f7fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df.replace(to_replace=\" ?\",value=np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7d8c96",
   "metadata": {},
   "source": [
    "Trasformiamo i _missing values_ nel valore più comune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bcfaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290ffbf9",
   "metadata": {},
   "source": [
    "Adesso il problema dei _missing values_ è risolto! Prima dell'encoding però è importante separare il _target_ dalle _feature_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03375af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['salary'],axis=1)\n",
    "y = df['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a22e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['workclass', 'marital-status', 'occupation','relationship', 'race', 'sex', 'native-country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9180bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first',sparse_output=False)\n",
    "\n",
    "for column in columns:\n",
    "    x[column] = encoder.fit_transform(x[[column]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06bc8ad",
   "metadata": {},
   "source": [
    "Separatamente codifichiamo il _target_ con un _label encoder_, usiamo il label encoder perché _salary_ è un attributo già binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd764d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416f9e5",
   "metadata": {},
   "source": [
    "Infine per uniformità dei dati eseguiamo il casting dell'intero contenuto del _Data Frame_ a _float_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f89ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.astype(float)\n",
    "y = y.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c0426",
   "metadata": {},
   "source": [
    "Infine eseguiamo la separazione tra _test set_ e _training set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e048559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7060796",
   "metadata": {},
   "source": [
    "Ora che abbiamo terminato il preprocessing e reso Salary un valore numerico possiamo permetterci di guardare una heatmap che mostri la correlazioni tra gli attributi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c7b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_df = x[['education-num','hours-per-week','age']]\n",
    "heat_df['salary'] = y\n",
    "\n",
    "corr = heat_df.corr(numeric_only=True)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=True)\n",
    "plt.title(\"Heatmap delle Correlazioni\", fontsize=16)\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db61016",
   "metadata": {},
   "source": [
    "## Addestramento dei Modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64faeca2",
   "metadata": {},
   "source": [
    "Prima di addestrare i modelli prepariamoci dei metodi che ci permettano di analizzarli:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49abfa06",
   "metadata": {},
   "source": [
    "Uno per mostrare il grafico della confusion matrix,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def matrice_confusione(y_test,y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix',fontsize = 14, fontweight = 'bold')\n",
    "    plt.ylabel('Vero')\n",
    "    plt.xlabel('Predetto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86b7a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico_scatole(risultati,alg):\n",
    "    sns.barplot(risultati)\n",
    "\n",
    "    plt.title(\"Prestazione \"+alg, fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(\"Valore (%)\")\n",
    "    plt.xlabel(\"Metrica\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219321c1",
   "metadata": {},
   "source": [
    "E uno che ci calcoli le statistiche in maniera dinamica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "def statistiche(y_test, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Precision': np.ceil(precision*100),\n",
    "        'Recall': np.ceil(recall*100),\n",
    "        'F1-Score':np.ceil(f1*100),\n",
    "    }, index=['Classe 0', 'Classe 1'])\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostra(y_test,y_pred,alg):\n",
    "    plt.figure(figsize=(18, 6)) \n",
    "    plt.subplot(1, 2, 1)\n",
    "    matrice_confusione(y_test,y_pred)\n",
    "    tmp = statistiche(y_test,y_pred)\n",
    "    print (tmp)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    grafico_scatole(tmp,alg)\n",
    "    results[alg] = tmp\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d00bc9",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dec_tree = tree.DecisionTreeClassifier(class_weight='balanced')\n",
    "dec_tree.fit(x_train,y_train)\n",
    "print(\"Modello Addestrato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399f162e",
   "metadata": {},
   "source": [
    "Adesso che il modello è stato addestrato andiamo a vedere come si comporta col _test set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2dff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dec_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c758ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostra(y_test,y_pred,\"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b57908a",
   "metadata": {},
   "source": [
    "Non sono male come risultati, ma il classificatore tende a essere restio nel predire la _classe negativa_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0838f5",
   "metadata": {},
   "source": [
    "### Support Vector Machine \n",
    "Ci muoviamo a questa famiglia di algoritmi, _sklearn_ ci fornisce 3 classi per la classificazione con SVM, useremo la versione LinearSVC, è molto simile al classico SVC, ma è più veloce, usa come kernel lineare (quindi bordi delle regioni delle classi sono linee rette) ed è implementato con una libreria più flessibile. Oltretutto inseriamo come argomento *class_weight = 'balanced'* cosicchè il problema della _class imbalance_ sia mitigato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f627d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm \n",
    "clf = svm.LinearSVC(class_weight = 'balanced')\n",
    "clf.fit(x_train,y_train)\n",
    "print(\"Modello Addestrato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02463af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostra(y_test,y_pred,\"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c27fe",
   "metadata": {},
   "source": [
    "### Nearest Neighbor\n",
    "L'ultimo algoritmo che useremo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c2c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(x_train,y_train)\n",
    "\n",
    "print(\"Modello Addestrato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbaca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a18f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostra(y_test,y_pred,\"Nearest Neighbor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27eb5ed",
   "metadata": {},
   "source": [
    "### Risultati Finali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e89690",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in results.keys():\n",
    "    print(k)\n",
    "    print(results.get(k))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,4))\n",
    "plt.subplot(1,3, 1)\n",
    "grafico_scatole(results[\"Decision Tree\"],\"Decision Tree\")\n",
    "plt.subplot(1,3,2)\n",
    "grafico_scatole(results[\"SVM\"],\"Support Vector Machines\")\n",
    "plt.subplot(1,3,3)\n",
    "grafico_scatole(results[\"Nearest Neighbor\"],\"Nearest Neighbor\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
