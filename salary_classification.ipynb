{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b2a4d17",
   "metadata": {},
   "source": [
    "## Salary Prediction Dataset \n",
    "\n",
    "Questo progetto si prepone di risolvere il problema della __Salary Prediction__ in versione *Classification*, quindi di raggruppare i dati in due classi:\n",
    "- _Salary <= 50k_ Per le persone il cui slario è predetto inferiore a 50k\n",
    "- _Salary > 50k_ Per l'inverso;\n",
    "\n",
    "Iniziamo aprendo il dataset dal folder apposito e leggendolo con _pandas_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad2b1a",
   "metadata": {},
   "source": [
    "## Salary Prediction Dataset \n",
    "\n",
    "Questo progetto si prepone di risolvere il problema della __Salary Prediction__ in versione *Classification*, quindi di raggruppare i record in due classi:\n",
    "- _Salary <= 50k_ Per le persone il cui slario è predetto inferiore a 50k\n",
    "- _Salary > 50k_ Per l'inverso;\n",
    "\n",
    "Iniziamo aprendo il dataset dal folder apposito e leggendolo con _pandas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae5754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(\"dataset\")\n",
    "df = pd.read_csv(\"salary.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1279b48",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "Cominciamo vedendo in che stato versa il Dataset cosicchè si possa capire che tipo di operazioni vanno svolte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d0180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb1a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee578827",
   "metadata": {},
   "source": [
    "Si può notare che tra i tipi delle colonne ci sono principalmente valori _object_, sicuramente servirà un'operazione di *encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c849a5",
   "metadata": {},
   "source": [
    "Strane queste colonne capital-gain e capital-loss, meglio dare un'occhiata più specifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac33279",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital-gain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e375fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital-gain'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553eba50",
   "metadata": {},
   "source": [
    "Capital-gain e capital-value essere inutili, precisamente, (facendo i conti una sola volta perché il numero di 0 nelle due colonne è lo stesso) si può dire che su 32561 tuple 29849 sono 0.\n",
    "Infatti impostando la semplice proporzione \n",
    "$$\n",
    "\\frac{29849}{32561} \\cdot 100 \\approx 91.6\\%\n",
    "$$  \n",
    "Capiamo che addirittura il _*91.6%*_ dei valori all'interno di queste due colonne è 0, questo è abbastanza per rimuovere entrambe le colonne per rendere il dataset più semplice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925703c0",
   "metadata": {},
   "source": [
    "Per capire più facilmente quanti siano gli zeri a confronto dei valori accettabili ecco anche una rappresentazione grafica, ma prima un leggero setup di _MathPlotLib_ per avere dei grafici più carini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b094d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': '#1d2021',\n",
    "    'axes.facecolor': '#201d16',\n",
    "    'axes.edgecolor': '#ebdbb2',\n",
    "    'axes.labelcolor': '#ebdbb2',\n",
    "    'xtick.color': '#ebdbb2',\n",
    "    'ytick.color': '#ebdbb2',\n",
    "    'text.color': '#ebdbb2',\n",
    "    'axes.titlecolor': '#ebdbb2',\n",
    "    'grid.color': '#3c3836',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6)) \n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[\"capital-loss\"],bins=100)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df[\"capital-gain\"], kde=False,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93347b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c72686",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"\\nColonna: {col}\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23082df6",
   "metadata": {},
   "source": [
    "Tramite l'output di questi ultimi metodi è possibile accorgersi che non sono presenti valori _null_, ma sono presenti molti _missing values_ marchiati con il carattere _?_ nelle colonne:\n",
    "- WorkClass\n",
    "- Occupation\n",
    "- Native Coutry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97380010",
   "metadata": {},
   "source": [
    "Inoltre, si può osservare che la colonna _education_ non si differenzia sostanzialmente da _education-num_, se non per il fatto che quest'ultima contiene valori numerici. Considerando che durante il preprocessing andremo ad applicare tecniche di _encoding_ sulle colonne con valori non numerici, è più conveniente mantenere _education-num_. Quest'ultima, infatti, rappresenta già un'ordinamento naturale dei livelli di istruzione, che andrebbe perso utilizzando algoritmi di encoding come il *One Hot Encoding*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a3901",
   "metadata": {},
   "source": [
    "Infine anche la colonna fnlwgt (Final Weight) è inutile perché rappresenta un peso usato nell'analisi demografica dei sondaggi che, nel contesto della classificazione è completamente inutile. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bdc6a1",
   "metadata": {},
   "source": [
    "Ora guardiamo un boxplot delle colonne numeriche, facciamoci un'idea degli _outlier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(df[[\"age\",\"hours-per-week\"]])\n",
    "plt.title(\"BoxPlot di Age e Hours Per Week\")\n",
    "plt.ylabel(\"Valore Numerico\")\n",
    "plt.xlabel(\"Attributo\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13294b5b",
   "metadata": {},
   "source": [
    "Ci sono dei valori lontani, ma non irrelistici quindi _non serve pulire gli outlier_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef3aa8",
   "metadata": {},
   "source": [
    "Infine vediamo qualche grafico per farci un'idea della distribuzione del _dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d5a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x=\"salary\")\n",
    "\n",
    "plt.title(\"Distribuzione dei salari\")\n",
    "plt.xlabel(\"Classe Salariale\")\n",
    "plt.ylabel(\"Numero di osservazioni\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b29f3f8",
   "metadata": {},
   "source": [
    "Da qui si può notare un grande _class imbalance_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce6405",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Cominciamo dalla rimozione delle colonne che erano risultate inutili dalla Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"capital-gain\", \"capital-loss\",\"education\",\"fnlwgt\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e332d7",
   "metadata": {},
   "source": [
    "Continuando procediamo alla rimozione dei duplicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bb4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd92e687",
   "metadata": {},
   "source": [
    "Per prima cosa rendiamo più facile le operazioni trasformando i _missing values ' ?'_  in _np.nan_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2836e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df.replace(to_replace=\" ?\",value=np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0fab32",
   "metadata": {},
   "source": [
    "Trasformiamo i _missing values_ nel valore più comune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27408639",
   "metadata": {},
   "source": [
    "Adesso il problema dei _missing values_ è risolto! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afe3c9e",
   "metadata": {},
   "source": [
    "Prima dell'encoding però è importante separare il _target_ dalle _feature_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d756cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['salary'],axis=1)\n",
    "y = df['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['workclass', 'marital-status', 'occupation','relationship', 'race', 'sex', 'native-country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de440cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first',sparse_output=False)\n",
    "\n",
    "for column in columns:\n",
    "    x[column] = encoder.fit_transform(x[[column]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56909c06",
   "metadata": {},
   "source": [
    "Separatamente codifichiamo il _target_ con un _label encoder_, visto che _salary_ è un attributo già binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde64d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de13db1",
   "metadata": {},
   "source": [
    "Infine per uniformità dei dati eseguiamo il casting dell'intero contenuto del _Data Frame_ a _float_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a234830",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.astype(float)\n",
    "y = y.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fa85c7",
   "metadata": {},
   "source": [
    "Poi eseguiamo la separazione tra _test set_ e _training set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf6e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d540a3",
   "metadata": {},
   "source": [
    "Infine per rendere più pratico il funzionamento di alcuni algoritmi di classificazione andiamo a svolgere la _normalizzazione_ dei dati di *X*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f65576",
   "metadata": {},
   "source": [
    "Anche se la scala dei valori numerici nel dataset non presenta squilibri eccessivi, per buona pratica si preferisce comunque applicare uno scaling, specialmente in vista dell’utilizzo di algoritmi come KNN e SVM, noti per essere sensibili alla scala delle feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3864833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "x_train = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20abe637",
   "metadata": {},
   "source": [
    "Ora che abbiamo terminato il preprocessing e reso Salary un valore numerico possiamo permetterci di guardare una heatmap che mostri la correlazioni tra gli attributi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3460dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_df = x[['education-num','hours-per-week','age']].copy()\n",
    "heat_df['salary'] = y\n",
    "\n",
    "corr = heat_df.corr(numeric_only=True)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=True)\n",
    "plt.title(\"Heatmap delle Correlazioni\", fontsize=16)\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d64b3e",
   "metadata": {},
   "source": [
    "## Addestramento dei Modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5062f6c",
   "metadata": {},
   "source": [
    "Prima di addestrare i modelli prepariamoci dei metodi che ci permettano di analizzarli:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f3439",
   "metadata": {},
   "source": [
    "Due per mostrare dei grafici "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653bfdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def matrice_confusione(y_test,y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix',fontsize = 14, fontweight = 'bold')\n",
    "    plt.ylabel('Vero')\n",
    "    plt.xlabel('Predetto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4879ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico_scatole(risultati,alg):\n",
    "    sns.barplot(risultati)\n",
    "\n",
    "    plt.title(\"Prestazione \"+alg, fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(\"Valore (%)\")\n",
    "    plt.xlabel(\"Metrica\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f19525",
   "metadata": {},
   "source": [
    "Uno che ci calcoli le statistiche in maniera dinamica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8825cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "def statistiche(y_test, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Precision': np.ceil(precision*100),\n",
    "        'Recall': np.ceil(recall*100),\n",
    "        'F1-Score':np.ceil(f1*100),\n",
    "    }, index=['Classe 0', 'Classe 1'])\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa084ad9",
   "metadata": {},
   "source": [
    "E uno che unisca tutte le funzioni un uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6867c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "def analizza(y_test,y_pred,alg):\n",
    "    plt.figure(figsize=(18, 6)) \n",
    "    plt.subplot(1, 2, 1)\n",
    "    matrice_confusione(y_test,y_pred)\n",
    "    tmp = statistiche(y_test,y_pred)\n",
    "    display(tmp)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    grafico_scatole(tmp,alg)\n",
    "    results[alg] = tmp\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2061482",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bf0807",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b47a4",
   "metadata": {},
   "source": [
    "Il primo algoritmo che useremo sarà il _Decision tree_, il più semplice e anche il primo studiato, importante è settare la flag *class_weight* come _balanced_ cosìcchè il problema della _class imbalance_ in __y__ sia mitigato, infatti questa flag va regolare il peso delle classi in modo tale che in relazione alla dimensione delle due il loro valore sia bilanciato "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f338565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dec_tree = tree.DecisionTreeClassifier(class_weight= \"balanced\")\n",
    "dec_tree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3346f258",
   "metadata": {},
   "source": [
    "Adesso che il modello è stato addestrato andiamo a vedere come si comporta col _test set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f33295",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dec_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analizza(y_test,y_pred,\"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f94b37f",
   "metadata": {},
   "source": [
    "Non sono male come risultati, ma il classificatore tende a essere restio nel predire la _classe positiva_ una classifica in base alla media dell'*F1-Score* sulla preditiva_ e quindi per la _classe 0_ abbiamo una bassa *Precision*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e070cdae",
   "metadata": {},
   "source": [
    "### Support Vector Machine \n",
    "Ci muoviamo a questa famiglia di algoritmi, _sklearn_ ci fornisce 3 classi per la classificazione con SVM, useremo la versione LinearSVC (*Support Vector Classification*), è molto simile al classico SVC, ma è più veloce, usa come kernel lineare ed è implementato con una libreria più flessibile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3da2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm \n",
    "svm_clf = svm.LinearSVC(class_weight = \"balanced\")\n",
    "svm_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecce2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analizza(y_test,y_pred,\"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d006a18",
   "metadata": {},
   "source": [
    "SVM presenta degli ottimi valori, anche lui predice con poca precisione la *classe 0*, però meglio di Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8abea7",
   "metadata": {},
   "source": [
    "### Nearest Neighbor\n",
    "Il valore di _k_ utilizzato sarà 9, questo perché scendendo con i valori il modello il modello perdeva di precision, salendo invece diventava troppo sensibile al *rumore*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816acfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=9)\n",
    "neigh.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60bb0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "analizza(y_test,y_pred,\"Nearest Neighbor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033c94af",
   "metadata": {},
   "source": [
    "KNN invece guadagna di *Precision*, ma perde di *Recall*, capiamo quindi che molti meno dei reali record $\\ge$ 50k sono individuati  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcddc050",
   "metadata": {},
   "source": [
    "### Percettrone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2b5f69",
   "metadata": {},
   "source": [
    "Ora ci muoviamo all'ANN con il _Percettrone_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ann = Perceptron(max_iter=1000, eta0=0.1, random_state=42)\n",
    "ann.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analizza(y_test,y_pred, \"Percettrone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cd1298",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe4ada9",
   "metadata": {},
   "source": [
    "Infine diamoci ai classificatori _ensemble_ con *Random Forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21344af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "ran_forest = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "ran_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ran_forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "analizza(y_test,y_pred, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9548b4",
   "metadata": {},
   "source": [
    "## Risultati Finali"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40758fd",
   "metadata": {},
   "source": [
    "Per prima cosa visualizziamo le statistiche in modo tabulare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204cb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in results.keys():\n",
    "    print(k)\n",
    "    display(results.get(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda396e",
   "metadata": {},
   "source": [
    "E poi dei comodi _boxplot_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6127c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 8)) \n",
    "\n",
    "for idx, (alg, df) in enumerate(results.items(), 1):\n",
    "    plt.subplot(2, 3, idx)\n",
    "    grafico_scatole(df, alg)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599b231b",
   "metadata": {},
   "source": [
    "Ora guardiamo una classifica in base alla media dell'*F1-Score* sulla predizione delle due classi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc51c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valori = []\n",
    "for alg,df in results.items():\n",
    "    valori.append({\n",
    "        'Modello': alg,\n",
    "        'Precision (avg)': df['Precision'].mean(),\n",
    "        'Recall (avg)': df['Recall'].mean(),\n",
    "        'F1-Score (avg)': df['F1-Score'].mean()\n",
    "    })\n",
    "\n",
    "valori = pd.DataFrame()\n",
    "display(valori.sort_values(by = 'F1-Score (avg)',ascending = False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
